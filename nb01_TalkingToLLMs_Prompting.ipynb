{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acaa284b",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4edb2",
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the saved API keys\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a creative writing assistant. Help users write compelling short stories.\"),\n",
    "    HumanMessage(\"Write a story about a robot learning to paint.\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559e24a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Practice tweaking the above cells with different models, different SYSTEM messages, different Human messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a coding tutor. Explain programming concepts clearly and provide simple examples.\"),\n",
    "    HumanMessage(\"Explain what a for loop is and give an example in Python.\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28192a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a career counselor. Provide thoughtful advice about career decisions and professional development.\"),\n",
    "    HumanMessage(\"I enjoy working with data and solving problems. I have a math background.\"),\n",
    "    HumanMessage(\"What career paths might be a good fit for me?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f358305",
   "metadata": {},
   "source": [
    "# Streaming Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c682adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36087549",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767eb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"You are a cooking assistant. Create a {meal_type} recipe using {ingredient} as the main ingredient\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{request}\")]\n",
    ")\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563db791",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"meal_type\": \"healthy dinner\", \"ingredient\": \"chicken\", \"request\": \"Make it easy to prepare\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0cdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae59198",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1778f56",
   "metadata": {},
   "source": [
    "# Structured Output\n",
    "\n",
    "https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a409e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83944031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic outout structure\n",
    "class JokeFormat(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(JokeFormat)\n",
    "\n",
    "joke = structured_llm.invoke(\"Tell me a joke about cats\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class BookRecommendation(BaseModel):\n",
    "    \"\"\"Book recommendation based on user preferences\"\"\"\n",
    "    title: str = Field(description=\"Title of the recommended book\")\n",
    "    author: str = Field(description=\"Author of the book\")\n",
    "    genre: str = Field(description=\"Primary genre of the book\")\n",
    "    difficulty: str = Field(description=\"Reading difficulty level: beginner, intermediate, advanced\")\n",
    "    reasoning: str = Field(description=\"Why this book is recommended for the user\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(BookRecommendation)\n",
    "\n",
    "output = structured_llm.invoke(\"Recommend a science fiction book for someone who enjoys space exploration themes\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bed832",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a film critic assistant. Use the following movie review to answer the question. If you don't know the answer based on the review, just say that you don't know. Keep your analysis concise and insightful.\n",
    "Question: {question} \n",
    "Review: {context} \n",
    "Analysis:\"\"\"\n",
    "\n",
    "file = open(\".\\data\\indianTales.txt\")\n",
    "text = file.read()\n",
    "\n",
    "class MovieAnalysis(BaseModel):\n",
    "    \"\"\"A model to analyze a movie review\"\"\"\n",
    "    overall_rating: str = Field(description=\"Overall sentiment: positive, negative, or mixed\")\n",
    "    key_strengths: list[str] = Field(description=\"Main strengths mentioned in the review\")\n",
    "    key_weaknesses: list[str] = Field(description=\"Main weaknesses mentioned in the review\")\n",
    "    recommendation: str = Field(description=\"Whether the reviewer recommends the movie\")\n",
    "\n",
    "prompt = ChatPromptTemplate([prompt_template])\n",
    "msg = prompt.invoke({\"question\":\"Analyze the overall sentiment and key points of this review.\", \"context\":text})\n",
    "\n",
    "structured_model = model.with_structured_output(MovieAnalysis)\n",
    "\n",
    "output = structured_model.invoke(msg)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a product review analyzer. Based on the given customer reviews, identify the main themes and sentiment patterns. Focus only on what customers are saying.\n",
    "Customer Reviews: {reviews} \n",
    "Key Themes:\"\"\"\n",
    "\n",
    "file = open(\".\\data\\\\animalResearch.txt\")\n",
    "text = file.read()\n",
    "\n",
    "prompt = ChatPromptTemplate([prompt_template])\n",
    "msg = prompt.invoke({\"reviews\":text})\n",
    "\n",
    "output = llm.invoke(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134bdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[12].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b3c15",
   "metadata": {},
   "source": [
    "# More Bigger Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63108a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "workout_template = \"\"\"Create a {duration} minute workout routine for: {fitness_goal}\n",
    "Include equipment needed and difficulty level.\n",
    "\n",
    "Format your response as:\n",
    "\n",
    "# {{Workout Name}}\n",
    "--------\n",
    "**Duration:** {duration} minutes  \n",
    "**Goal:** {{goal}}  \n",
    "**Equipment:** {{equipment list}}  \n",
    "**Difficulty:** {{level}}\n",
    "\n",
    "## Exercises:\n",
    "{{exercise list with reps/sets}}\n",
    "\"\"\"\n",
    "question = workout_template.format(duration=\"30\", fitness_goal=\"building core strength\")\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response =  model.invoke(workout_template.format(duration=\"20\", fitness_goal=\"improving flexibility\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec349e40",
   "metadata": {},
   "source": [
    "## Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "prompt = \"\"\"You are a travel planning assistant. Create a 4-day itinerary for {destination}. For each day, suggest 3 main activities or attractions in this format:\n",
    "\n",
    "## Day 1: {{Theme}}\n",
    "1. **{{Activity 1}}** - {{brief description}}\n",
    "2. **{{Activity 2}}** - {{brief description}}\n",
    "3. **{{Activity 3}}** - {{brief description}}\n",
    "----\n",
    "## Day 2: {{Theme}}\n",
    "1. **{{Activity 1}}** - {{brief description}}\n",
    "2. **{{Activity 2}}** - {{brief description}}\n",
    "3. **{{Activity 3}}** - {{brief description}}\n",
    "----\n",
    "## Day 3: {{Theme}}\n",
    "1. **{{Activity 1}}** - {{brief description}}\n",
    "2. **{{Activity 2}}** - {{brief description}}\n",
    "3. **{{Activity 3}}** - {{brief description}}\n",
    "----\n",
    "## Day 4: {{Theme}}\n",
    "1. **{{Activity 1}}** - {{brief description}}\n",
    "2. **{{Activity 2}}** - {{brief description}}\n",
    "3. **{{Activity 3}}** - {{brief description}}\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke(prompt.format(destination=\"Tokyo, Japan for first-time visitors\"))\n",
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd3aa7",
   "metadata": {},
   "source": [
    "## Example with sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88348804",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short report on the topic {focus}. Divide the report into easily digestable sections. You have to use prior knowledge. While writing the report use the following instructions:\n",
    "        \n",
    "1. Create a report structure using markdown formatting: Create a minimum of 4 sections.\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "2. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "3. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "4. Write a summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 2000 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "        \n",
    "5. Write a Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "- [1] Link or Document name\n",
    "- [2] Link or Document name\n",
    "\n",
    "6. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "        \n",
    "7. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "response = model.invoke(prompt_template.format(focus=\"Machine Learning in daily use operating systems\"))\n",
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Write a detailed technical report on the mathematical topic: {topic}.\n",
    "\n",
    "Structure the report into the following sections, each clearly separated with appropriate Markdown headings (#, ##):\n",
    "\n",
    "# Introduction\n",
    "\n",
    "{{Give a clear, concise overview of the topic.}}\n",
    "\n",
    "{{Explain its significance and typical applications.}}\n",
    "\n",
    "# Mathematical Theory\n",
    "\n",
    "{{Describe the core mathematical foundations in detail.}}\n",
    "\n",
    "{{Include important definitions, theorems, proofs, and examples where relevant.}}\n",
    "\n",
    "# Latest Open Problems\n",
    "\n",
    "{{Discuss major current research challenges or unresolved questions in the field.}}\n",
    "\n",
    "# Reference recent papers or developments (with citations).\n",
    "\n",
    "# Future Directions\n",
    "\n",
    "{{Suggest possible paths for future research or applications.}}\n",
    "\n",
    "{{Discuss emerging trends and technologies that might impact this area.}}\n",
    "\n",
    "# References\n",
    "\n",
    "List all sources cited, preferably in a simple numbered list or BibTeX-style.\n",
    "\n",
    "Use appropriate LaTeX-style formatting (with $$ for equations if needed) for mathematical expressions inside the Markdown.\n",
    "Write in a formal and precise tone, suitable for a technical audience.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = model.invoke(prompt_template.format(topic=\"Machine Learning in stock predictions\"))\n",
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a4501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
