{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7a44cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.28-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.3-cp39-cp39-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.3-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp39-cp39-macosx_10_9_universal2.whl (207 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.28-py3-none-any.whl (384 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading orjson-3.11.3-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp39-cp39-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.6/640.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tenacity, SQLAlchemy, sniffio, PyYAML, pydantic-core, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, async-timeout, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [langchain];237m━\u001b[0m \u001b[32m26/27\u001b[0m [langchain]core]zer]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.43 annotated-types-0.7.0 anyio-4.10.0 async-timeout-4.0.3 certifi-2025.8.3 charset_normalizer-3.4.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.28 orjson-3.11.3 pydantic-2.11.9 pydantic-core-2.33.2 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf11c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c616bc7",
   "metadata": {},
   "source": [
    "# Learning to have conversation with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ac8343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Using cached langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-groq) (0.3.76)\n",
      "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
      "  Using cached groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.30.0->langchain-groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.28)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rohitjg/Desktop/code/MAT496/.venv/lib/python3.9/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n",
      "Using cached langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
      "Using cached groq-0.31.1-py3-none-any.whl (134 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq, langchain-groq\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-groq]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 groq-0.31.1 langchain-groq-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89a6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a model\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37126d86",
   "metadata": {},
   "source": [
    "### Create your tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63524d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def salty() -> str:\n",
    "    \"\"\" Call this tool if the food is salty\"\"\"\n",
    "    return \"Its Salty\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sour() -> str:\n",
    "    \"\"\" Call this tool if the food is sour\"\"\"\n",
    "    return \"Its Sour\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sweet() -> str:\n",
    "    \"\"\" Call this tool if the food is sweet\"\"\"\n",
    "    return \"Its Sweet\"\n",
    "\n",
    "@tool\n",
    "def bitter() -> str:\n",
    "    \"\"\" Call this tool if the food is bitter\"\"\"\n",
    "    return \"Its Bitter\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97bf49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [bitter, sour, sweet, salty]\n",
    "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55e761b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a tool calling Agent by binding a list of tools to the llm\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95042e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# This will store all converation\n",
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbabc17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"I just had some French fries. What does it taste like?\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99a1a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcaa5020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there was a tool call, execute the tool and append the tool output in the converation\n",
    "\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6ac75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"This pretzel is making me thirsty... what taste is it?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ef1d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4207a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='m4e3zhh4c')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a19930cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='m4e3zhh4c'),\n",
       " HumanMessage(content='But i added sugar to it', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"But i added sugar to it\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4a1f598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='m4e3zhh4c'),\n",
       " HumanMessage(content='But i added sugar to it', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " ToolMessage(content='Its Sweet', name='sweet', tool_call_id='19e7s9802')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the tool, append the response\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8658bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='m4e3zhh4c'),\n",
       " HumanMessage(content='But i added sugar to it', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " ToolMessage(content='Its Sweet', name='sweet', tool_call_id='19e7s9802'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm not aware of your personal relationships or circumstances. Our conversation just started with discussing food tastes. If you'd like to talk about something else, I'm here to listen and help if I can.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 551, 'total_tokens': 593, 'completion_time': 0.15067151, 'prompt_time': 0.050295261, 'queue_time': 0.047079809, 'total_time': 0.200966771}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0f365b64-66fe-4534-b6a8-af9a7cbf5293-0', usage_metadata={'input_tokens': 551, 'output_tokens': 42, 'total_tokens': 593}),\n",
       " HumanMessage(content='I’m stranded on a desert island and all I have are crackers. What taste will keep me alive?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'hvhb703ad', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 623, 'total_tokens': 632, 'completion_time': 0.002458235, 'prompt_time': 0.055147832, 'queue_time': 0.045973557, 'total_time': 0.057606067}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--73136dd1-621d-4d87-9228-a3134af3ae67-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'hvhb703ad', 'type': 'tool_call'}], usage_metadata={'input_tokens': 623, 'output_tokens': 9, 'total_tokens': 632})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see, if the model remebers the context\n",
    "chat_history.append(HumanMessage(content=\"I’m stranded on a desert island and all I have are crackers. What taste will keep me alive?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1c1a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot which can taste food, and also recommend kind of food the user is craving. Depending on the conversation, either respond the question, or show taste of the food/craving the user has with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your input is incomplete. Please provide more details or specify the food you'd like me to taste or recommend.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 388, 'total_tokens': 411, 'completion_time': 0.097957414, 'prompt_time': 0.033485955, 'queue_time': 0.052154645, 'total_time': 0.131443369}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0856438a-67c4-4227-afe1-aedb00b51251-0', usage_metadata={'input_tokens': 388, 'output_tokens': 23, 'total_tokens': 411}),\n",
       " HumanMessage(content='I just had some French fries. What does it taste like?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9eakavyy2', 'function': {'arguments': 'null', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 433, 'total_tokens': 441, 'completion_time': 0.038598624, 'prompt_time': 0.040754806, 'queue_time': 0.055474054, 'total_time': 0.07935343}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a427857e-dda1-464f-b1d7-f2637d2ba070-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': '9eakavyy2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 433, 'output_tokens': 8, 'total_tokens': 441}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='9eakavyy2'),\n",
       " HumanMessage(content='This pretzel is making me thirsty... what taste is it?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'm4e3zhh4c', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 473, 'total_tokens': 482, 'completion_time': 0.02450578, 'prompt_time': 0.042696362, 'queue_time': 0.046168407, 'total_time': 0.067202142}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aef6dc04-04bb-42e6-bdde-1f7cfb036e59-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'm4e3zhh4c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 9, 'total_tokens': 482}),\n",
       " ToolMessage(content='Its Salty', name='salty', tool_call_id='m4e3zhh4c'),\n",
       " HumanMessage(content='But i added sugar to it', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '19e7s9802', 'function': {'arguments': '{}', 'name': 'sweet'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 506, 'total_tokens': 515, 'completion_time': 0.002422356, 'prompt_time': 0.045799062, 'queue_time': 0.047053927, 'total_time': 0.048221418}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74084ba-150a-48bc-9278-bea40191f308-0', tool_calls=[{'name': 'sweet', 'args': {}, 'id': '19e7s9802', 'type': 'tool_call'}], usage_metadata={'input_tokens': 506, 'output_tokens': 9, 'total_tokens': 515}),\n",
       " ToolMessage(content='Its Sweet', name='sweet', tool_call_id='19e7s9802'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm not aware of your personal relationships or circumstances. Our conversation just started with discussing food tastes. If you'd like to talk about something else, I'm here to listen and help if I can.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 551, 'total_tokens': 593, 'completion_time': 0.15067151, 'prompt_time': 0.050295261, 'queue_time': 0.047079809, 'total_time': 0.200966771}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0f365b64-66fe-4534-b6a8-af9a7cbf5293-0', usage_metadata={'input_tokens': 551, 'output_tokens': 42, 'total_tokens': 593}),\n",
       " HumanMessage(content='I’m stranded on a desert island and all I have are crackers. What taste will keep me alive?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'hvhb703ad', 'function': {'arguments': '{}', 'name': 'salty'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 623, 'total_tokens': 632, 'completion_time': 0.002458235, 'prompt_time': 0.055147832, 'queue_time': 0.045973557, 'total_time': 0.057606067}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--73136dd1-621d-4d87-9228-a3134af3ae67-0', tool_calls=[{'name': 'salty', 'args': {}, 'id': 'hvhb703ad', 'type': 'tool_call'}], usage_metadata={'input_tokens': 623, 'output_tokens': 9, 'total_tokens': 632}),\n",
       " HumanMessage(content='A dragon offered me a lemon drop as a peace treaty. How does it taste?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'ac0csx7h3', 'function': {'arguments': '{}', 'name': 'sour'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 658, 'total_tokens': 667, 'completion_time': 0.017617425, 'prompt_time': 0.061874291, 'queue_time': 0.050512058, 'total_time': 0.079491716}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d842da7c-df04-4476-b4f5-4a7fcb9ec925-0', tool_calls=[{'name': 'sour', 'args': {}, 'id': 'ac0csx7h3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 658, 'output_tokens': 9, 'total_tokens': 667})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"A dragon offered me a lemon drop as a peace treaty. How does it taste?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
